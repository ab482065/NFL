{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:02:15.761085Z",
     "start_time": "2021-03-12T17:02:15.732007Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from   sklearn.compose            import *\n",
    "from   sklearn.ensemble           import RandomForestClassifier, GradientBoostingClassifier\n",
    "from   sklearn.impute             import *\n",
    "from   sklearn.metrics            import confusion_matrix, accuracy_score\n",
    "from   sklearn.model_selection    import RandomizedSearchCV, train_test_split\n",
    "from   sklearn.pipeline           import Pipeline\n",
    "from   sklearn.preprocessing      import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:15:32.379602Z",
     "start_time": "2021-03-12T17:15:05.998404Z"
    }
   },
   "outputs": [],
   "source": [
    "'https://github.com/shahv1057/NFL_4thdown/blob/main/data/play_by_play_2018.csv.gz'\n",
    "years = [2018,2019,2020] # Look at last three NFL seasons\n",
    "data = pd.DataFrame()\n",
    "for year in years:  # Import data for each year\n",
    "    year_data = pd.read_csv('https://github.com/shahv1057/NFL_4thdown/blob/main/data/'\\\n",
    "                         'play_by_play_' + str(year) + '.csv.gz?raw=True',\n",
    "                         compression='gzip', low_memory=False)\n",
    "    data = data.append(year_data, sort=False)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T18:53:06.393519Z",
     "start_time": "2021-03-08T18:22:17.292Z"
    }
   },
   "source": [
    "# Target Tranformation \n",
    "I am trying to answer the question of what play type an NFL team would choose, given a specific pre-play 4th down situation. As a result, I filter the data for only rows that can be considered \"pre-play\" to avoid any data leakage, and then split the data into my X and y dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:16:31.865370Z",
     "start_time": "2021-03-12T17:16:30.540827Z"
    }
   },
   "outputs": [],
   "source": [
    "y_classes = ['PASS','RUSH','FIELD_GOAL','PUNT']\n",
    "data = data[(data['play_type_nfl'].isin(y_classes))&(data['down']==4)]\n",
    "Xdf = data.drop(['play_type_nfl'],axis=1)\n",
    "ydf = data['play_type_nfl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:16:33.185030Z",
     "start_time": "2021-03-12T17:16:33.061873Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xdf, ydf, test_size=.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:17:12.055002Z",
     "start_time": "2021-03-12T17:17:12.047085Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_data(X):\n",
    "    \n",
    "    \"\"\"\n",
    "    Column filtering: Only include features \n",
    "    that would be available in a game situation before the play\n",
    "    begins. \n",
    "    Custom feature engineering: Numerically represent\n",
    "    yard line  and bin score_differential into categorical game\n",
    "    score situations\n",
    "    \"\"\"\n",
    "    \n",
    "    Xdf_c = X.copy()\n",
    "    pre_play_features = [\n",
    "     'posteam', \n",
    "     'defteam',\n",
    "     'quarter_seconds_remaining',\n",
    "     'half_seconds_remaining',\n",
    "     'game_seconds_remaining',\n",
    "     'game_half',\n",
    "     'qtr',\n",
    "     'goal_to_go',\n",
    "     'yrdln',\n",
    "     'ydstogo',\n",
    "     'posteam_timeouts_remaining',\n",
    "     'defteam_timeouts_remaining',\n",
    "     'score_differential',\n",
    "     'season'   \n",
    "     ]\n",
    "    Xdf_c = Xdf_c[pre_play_features]\n",
    "    Xdf_c['ydstogo'] = Xdf_c['ydstogo'].astype(float)\n",
    "    Xdf_c['score_differential'] = pd.cut(Xdf_c['score_differential'],bins=[-100,-17,-12,-9,-4,0,4,9,12,17,100])\n",
    "    def convert_yd_line_vars(posteam,ydline):\n",
    "        if type(ydline)==str:\n",
    "            newydline = ydline.split()\n",
    "            if ydline == '50':\n",
    "                return float(ydline)\n",
    "            elif posteam == newydline[0]:\n",
    "                return float(newydline[1])\n",
    "            else:\n",
    "                return 100 - float(newydline[1])\n",
    "        else:\n",
    "            return np.nan\n",
    "    Xdf_c['yrdln'] = Xdf_c.apply(lambda x: convert_yd_line_vars(x['posteam'], x['yrdln']), axis=1)\n",
    "    return Xdf_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Random Forest Classifier\n",
    "Built my Pipeline with three steps:\n",
    "\n",
    "**1) Column Selection & Transformation**: Apply my filter_data Function Transformer \n",
    "\n",
    "**2) Preprocessing**: Impute continuous variables, and impute & one-hot-encode categorical variables\n",
    "\n",
    "**3) Fit**: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:20:58.736616Z",
     "start_time": "2021-03-12T17:20:57.660503Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = filter_data(X_train).dtypes != float\n",
    "con_pipe = Pipeline([('imputer', SimpleImputer(strategy='median', add_indicator=True))\n",
    "                    ])\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "                     ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "                    ])\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe,  categorical_columns),\n",
    "                                   ('continuous',  con_pipe, ~categorical_columns),\n",
    "                                   ])\n",
    "pipe_rf = Pipeline([\n",
    "    ('transform',FunctionTransformer(filter_data,validate=False)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('rf',RandomForestClassifier(\n",
    "                                ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters with Randomized Cross Validation Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:24:03.372111Z",
     "start_time": "2021-03-12T17:21:22.021113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('transform',\n",
       "                                              FunctionTransformer(func=<function filter_data at 0x156d780d0>)),\n",
       "                                             ('preprocessing',\n",
       "                                              ColumnTransformer(transformers=[('categorical',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer(add_indicator=True,\n",
       "                                                                                                              strategy='most_frequent')),\n",
       "                                                                                               ('ohe',\n",
       "                                                                                                OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                               posteam                        True\n",
       "defteam                        True\n",
       "qua...\n",
       "posteam_timeouts_remaining     True\n",
       "defteam_timeouts_remaining     True\n",
       "score_differential            False\n",
       "season                        False\n",
       "dtype: bool)])),\n",
       "                                             ('rf', RandomForestClassifier())]),\n",
       "                   n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'rf__criterion': ['gini', 'entropy'],\n",
       "                                        'rf__max_features': ['auto', 'log2',\n",
       "                                                             'sqrt'],\n",
       "                                        'rf__min_samples_leaf': array([1, 3, 5, 7]),\n",
       "                                        'rf__n_estimators': [10, 50, 100]},\n",
       "                   scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_hyperparams = dict(rf__criterion        = ['gini', 'entropy'],      # Loss function to split on\n",
    "                      rf__min_samples_leaf = np.arange(1, 8, 2),       # Avoid overfitting by stopping splits on low sample leaves\n",
    "                      rf__max_features     = [\"auto\", \"log2\", 'sqrt'], # Number of features choose from to split on at every tree node\n",
    "                      rf__n_estimators     = [10,50,100]               # Number of Trees, improve generalization\n",
    "                     )\n",
    "\n",
    "rf_rand_cv = RandomizedSearchCV(estimator=pipe_rf, \n",
    "                                param_distributions=rf_hyperparams, \n",
    "                                n_iter=25, \n",
    "                                cv=5, \n",
    "                                n_jobs=-1,\n",
    "                                verbose=True,\n",
    "                                scoring='accuracy')\n",
    "rf_rand_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Best Estimator Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:24:08.101165Z",
     "start_time": "2021-03-12T17:24:03.375727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 FunctionTransformer(func=<function filter_data at 0x156d780d0>)),\n",
       "                ('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  posteam                        True\n",
       "defteam                        True\n",
       "quarter_seconds_remaining     False\n",
       "half_se...\n",
       "                                                                                 strategy='median'))]),\n",
       "                                                  posteam                       False\n",
       "defteam                       False\n",
       "quarter_seconds_remaining      True\n",
       "half_seconds_remaining         True\n",
       "game_seconds_remaining         True\n",
       "game_half                     False\n",
       "qtr                           False\n",
       "goal_to_go                    False\n",
       "yrdln                          True\n",
       "ydstogo                        True\n",
       "posteam_timeouts_remaining     True\n",
       "defteam_timeouts_remaining     True\n",
       "score_differential            False\n",
       "season                        False\n",
       "dtype: bool)])),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(criterion='entropy',\n",
       "                                        max_features='sqrt'))])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    ('transform',FunctionTransformer(filter_data,validate=False)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('rf',rf_rand_cv.best_estimator_['rf'])\n",
    "])\n",
    "pipe_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Go-For-It metric\n",
    "Negate the impact of interchanging Pass or Rush to address the real world application of classifying whether or not the team decides to \"go for it\" on the 4th down play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:24:08.114915Z",
     "start_time": "2021-03-12T17:24:08.106099Z"
    }
   },
   "outputs": [],
   "source": [
    "def go_for_it_metric(y_true,y_pred):\n",
    "    acc = []\n",
    "    go_for_it = ['PASS','RUSH']\n",
    "    return accuracy_score(np.isin(y_true,go_for_it),np.isin(y_pred,go_for_it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Evaluation\n",
    "Output confusion matrix, overall accuracy score, class specific accuracy, and \"go_for_it\" industry-specific metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:24:08.578364Z",
     "start_time": "2021-03-12T17:24:08.120353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Confusion Matrix:\n",
      "            PASS_PRED  RUSH_PRED  FIELD_GOAL_PRED  PUNT_PRED\n",
      "PASS               58         21               41         54\n",
      "RUSH               14         52               10         43\n",
      "FIELD_GOAL          7          5              403          9\n",
      "PUNT                4          5               10       1040\n",
      "\n",
      "-----------------------------\n",
      "Overall Accuracy Score: 87.44%\n",
      "\n",
      "-----------------------------\n",
      "Class Accuracy Scores:\n",
      "PASS: 33.33%\n",
      "RUSH: 43.70%\n",
      "FIELD_GOAL: 95.05%\n",
      "PUNT: 98.21%\n",
      "\n",
      "Go-For-It Accuracy Score: 90.48%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe_rf.predict(X_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred, labels=y_classes)\n",
    "print('---------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(cm,columns=[y+'_PRED' for y in y_classes],index=y_classes))\n",
    "print ()\n",
    "print('-----------------------------')\n",
    "print (f\"Overall Accuracy Score: {accuracy_score(y_valid,y_pred)*100:.2f}%\",end='\\n\\n')\n",
    "print('-----------------------------')\n",
    "print (\"Class Accuracy Scores:\",end='\\n')\n",
    "for play_type,acc in (sorted(zip(y_classes,cm.diagonal()/cm.sum(axis=1)),key = lambda x: x[1])):\n",
    "    print (f\"{play_type}: {acc*100:.2f}%\")\n",
    "print ()\n",
    "print(f'Go-For-It Accuracy Score: {go_for_it_metric(y_valid,y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Gradient Boosting Classifier\n",
    "Built my Pipeline with three steps:\n",
    "\n",
    "**1) Column Selection & Transformation**: Apply my filter_data Function Transformer \n",
    "\n",
    "**2) Preprocessing**: Impute continuous variables, and impute & one-hot-encode categorical variables\n",
    "\n",
    "**3) Fit**: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:26:24.653104Z",
     "start_time": "2021-03-12T17:26:23.671091Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = filter_data(X_train).dtypes != float\n",
    "con_pipe = Pipeline([\n",
    "                     ('imputer', SimpleImputer(strategy='median', add_indicator=True))\n",
    "                    ])\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "                     ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "                    ])\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe,  categorical_columns),\n",
    "                                   ('continuous',  con_pipe, ~categorical_columns),\n",
    "                                   ])\n",
    "pipe_gb = Pipeline([\n",
    "    ('transform',FunctionTransformer(filter_data,validate=False)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('gb',GradientBoostingClassifier(\n",
    "                            ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters with Randomized Cross Validation Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:28:24.925440Z",
     "start_time": "2021-03-12T17:26:24.656636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('transform',\n",
       "                                              FunctionTransformer(func=<function filter_data at 0x156d780d0>)),\n",
       "                                             ('preprocessing',\n",
       "                                              ColumnTransformer(transformers=[('categorical',\n",
       "                                                                               Pipeline(steps=[('imputer',\n",
       "                                                                                                SimpleImputer(add_indicator=True,\n",
       "                                                                                                              strategy='most_frequent')),\n",
       "                                                                                               ('ohe',\n",
       "                                                                                                OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                               posteam                        True\n",
       "defteam                        True\n",
       "qua...\n",
       "game_half                     False\n",
       "qtr                           False\n",
       "goal_to_go                    False\n",
       "yrdln                          True\n",
       "ydstogo                        True\n",
       "posteam_timeouts_remaining     True\n",
       "defteam_timeouts_remaining     True\n",
       "score_differential            False\n",
       "season                        False\n",
       "dtype: bool)])),\n",
       "                                             ('gb',\n",
       "                                              GradientBoostingClassifier())]),\n",
       "                   n_iter=12, n_jobs=-1,\n",
       "                   param_distributions={'gb__learning_rate': [0.15, 0.1, 0.05,\n",
       "                                                              0.01],\n",
       "                                        'gb__n_estimators': [10, 50, 100]},\n",
       "                   scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_hyperparams = dict(gb__learning_rate = [0.15,0.1,0.05,0.01], # How quickly should GB Classifier adjust weights to get to optimal value  \n",
    "                       gb__n_estimators  = [10,50,100], # Number of trees\n",
    "                      )\n",
    "\n",
    "gb_rand_cv = RandomizedSearchCV(estimator=pipe_gb, \n",
    "                                param_distributions=gb_hyperparams, \n",
    "                                n_iter=12, \n",
    "                                cv=5, \n",
    "                                n_jobs=-1,\n",
    "                                verbose=True,\n",
    "                                scoring='accuracy')\n",
    "gb_rand_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:28:31.679948Z",
     "start_time": "2021-03-12T17:28:24.929009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 FunctionTransformer(func=<function filter_data at 0x156d780d0>)),\n",
       "                ('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  posteam                        True\n",
       "defteam                        True\n",
       "quarter_seconds_remaining     False\n",
       "half_se...\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median'))]),\n",
       "                                                  posteam                       False\n",
       "defteam                       False\n",
       "quarter_seconds_remaining      True\n",
       "half_seconds_remaining         True\n",
       "game_seconds_remaining         True\n",
       "game_half                     False\n",
       "qtr                           False\n",
       "goal_to_go                    False\n",
       "yrdln                          True\n",
       "ydstogo                        True\n",
       "posteam_timeouts_remaining     True\n",
       "defteam_timeouts_remaining     True\n",
       "score_differential            False\n",
       "season                        False\n",
       "dtype: bool)])),\n",
       "                ('gb', GradientBoostingClassifier())])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_gb = Pipeline([\n",
    "    ('transform',FunctionTransformer(filter_data,validate=False)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('gb',gb_rand_cv.best_estimator_['gb'])\n",
    "])\n",
    "pipe_gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Evaluation\n",
    "Output confusion matrix, overall accuracy score, class specific accuracy, and \"go_for_it\" industry-specific metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:31:32.772579Z",
     "start_time": "2021-03-12T17:31:32.498196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Confusion Matrix:\n",
      "            PASS_PRED  RUSH_PRED  FIELD_GOAL_PRED  PUNT_PRED\n",
      "PASS               79         21               34         40\n",
      "RUSH               19         66                5         29\n",
      "FIELD_GOAL          6         11              399          8\n",
      "PUNT               12          8                7       1032\n",
      "\n",
      "-----------------------------\n",
      "Overall Accuracy Score: 88.74%\n",
      "\n",
      "-----------------------------\n",
      "Class Accuracy Scores:\n",
      "PASS: 45.40%\n",
      "RUSH: 55.46%\n",
      "FIELD_GOAL: 94.10%\n",
      "PUNT: 97.45%\n",
      "-----------------------------\n",
      "Go-For-It Accuracy Score: 91.84%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe_gb.predict(X_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred, labels=y_classes)\n",
    "print('---------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(cm,columns=[y+'_PRED' for y in y_classes],index=y_classes))\n",
    "print ()\n",
    "print('-----------------------------')\n",
    "print (f\"Overall Accuracy Score: {accuracy_score(y_valid,y_pred)*100:.2f}%\",end='\\n\\n')\n",
    "print('-----------------------------')\n",
    "print (\"Class Accuracy Scores:\",end='\\n')\n",
    "for play_type,acc in (sorted(zip(y_classes,cm.diagonal()/cm.sum(axis=1)),key = lambda x: x[1])):\n",
    "    print (f\"{play_type}: {acc*100:.2f}%\")\n",
    "print('-----------------------------')\n",
    "print(f'Go-For-It Accuracy Score: {go_for_it_metric(y_valid,y_pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "Choose Gradient Boosting Classifier Model as Final Model as it has a higher Overall Accuracy and Go-For-It accuracy on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:31:34.670048Z",
     "start_time": "2021-03-12T17:31:34.609627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('transform',\n",
      "                 FunctionTransformer(func=<function filter_data at 0x156d780d0>)),\n",
      "                ('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('categorical',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(add_indicator=True,\n",
      "                                                                                 strategy='most_frequent')),\n",
      "                                                                  ('ohe',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  posteam                        True\n",
      "defteam                        True\n",
      "quarter_seconds_remaining     False\n",
      "half_se...\n",
      "                                                                   SimpleImputer(add_indicator=True,\n",
      "                                                                                 strategy='median'))]),\n",
      "                                                  posteam                       False\n",
      "defteam                       False\n",
      "quarter_seconds_remaining      True\n",
      "half_seconds_remaining         True\n",
      "game_seconds_remaining         True\n",
      "game_half                     False\n",
      "qtr                           False\n",
      "goal_to_go                    False\n",
      "yrdln                          True\n",
      "ydstogo                        True\n",
      "posteam_timeouts_remaining     True\n",
      "defteam_timeouts_remaining     True\n",
      "score_differential            False\n",
      "season                        False\n",
      "dtype: bool)])),\n",
      "                ('gb', GradientBoostingClassifier())])\n"
     ]
    }
   ],
   "source": [
    "final_model = pipe_gb\n",
    "print (final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:31:36.898621Z",
     "start_time": "2021-03-12T17:31:36.831433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('transform',\n",
       "   FunctionTransformer(func=<function filter_data at 0x156d780d0>)),\n",
       "  ('preprocessing',\n",
       "   ColumnTransformer(transformers=[('categorical',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(add_indicator=True,\n",
       "                                                                   strategy='most_frequent')),\n",
       "                                                    ('ohe',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    posteam                        True\n",
       "   defteam                        True\n",
       "   quarter_seconds_remaining     False\n",
       "   half_seconds_remaining        False\n",
       "   game_seconds_remaining        False\n",
       "   game_half                      True\n",
       "   qtr                            True\n",
       "   goal_to_go                     True\n",
       "   yrdln                         False\n",
       "   ydstogo                       False\n",
       "   poste...\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(add_indicator=True,\n",
       "                                                                   strategy='median'))]),\n",
       "                                    posteam                       False\n",
       "   defteam                       False\n",
       "   quarter_seconds_remaining      True\n",
       "   half_seconds_remaining         True\n",
       "   game_seconds_remaining         True\n",
       "   game_half                     False\n",
       "   qtr                           False\n",
       "   goal_to_go                    False\n",
       "   yrdln                          True\n",
       "   ydstogo                        True\n",
       "   posteam_timeouts_remaining     True\n",
       "   defteam_timeouts_remaining     True\n",
       "   score_differential            False\n",
       "   season                        False\n",
       "   dtype: bool)])),\n",
       "  ('gb', GradientBoostingClassifier())],\n",
       " 'verbose': False,\n",
       " 'transform': FunctionTransformer(func=<function filter_data at 0x156d780d0>),\n",
       " 'preprocessing': ColumnTransformer(transformers=[('categorical',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                 strategy='most_frequent')),\n",
       "                                                  ('ohe',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  posteam                        True\n",
       " defteam                        True\n",
       " quarter_seconds_remaining     False\n",
       " half_seconds_remaining        False\n",
       " game_seconds_remaining        False\n",
       " game_half                      True\n",
       " qtr                            True\n",
       " goal_to_go                     True\n",
       " yrdln                         False\n",
       " ydstogo                       False\n",
       " poste...\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                 strategy='median'))]),\n",
       "                                  posteam                       False\n",
       " defteam                       False\n",
       " quarter_seconds_remaining      True\n",
       " half_seconds_remaining         True\n",
       " game_seconds_remaining         True\n",
       " game_half                     False\n",
       " qtr                           False\n",
       " goal_to_go                    False\n",
       " yrdln                          True\n",
       " ydstogo                        True\n",
       " posteam_timeouts_remaining     True\n",
       " defteam_timeouts_remaining     True\n",
       " score_differential            False\n",
       " season                        False\n",
       " dtype: bool)]),\n",
       " 'gb': GradientBoostingClassifier(),\n",
       " 'transform__accept_sparse': False,\n",
       " 'transform__check_inverse': True,\n",
       " 'transform__func': <function __main__.filter_data(X)>,\n",
       " 'transform__inv_kw_args': None,\n",
       " 'transform__inverse_func': None,\n",
       " 'transform__kw_args': None,\n",
       " 'transform__validate': False,\n",
       " 'preprocessing__n_jobs': None,\n",
       " 'preprocessing__remainder': 'drop',\n",
       " 'preprocessing__sparse_threshold': 0.3,\n",
       " 'preprocessing__transformer_weights': None,\n",
       " 'preprocessing__transformers': [('categorical',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(add_indicator=True, strategy='most_frequent')),\n",
       "                   ('ohe', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   posteam                        True\n",
       "   defteam                        True\n",
       "   quarter_seconds_remaining     False\n",
       "   half_seconds_remaining        False\n",
       "   game_seconds_remaining        False\n",
       "   game_half                      True\n",
       "   qtr                            True\n",
       "   goal_to_go                     True\n",
       "   yrdln                         False\n",
       "   ydstogo                       False\n",
       "   posteam_timeouts_remaining    False\n",
       "   defteam_timeouts_remaining    False\n",
       "   score_differential             True\n",
       "   season                         True\n",
       "   dtype: bool),\n",
       "  ('continuous',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(add_indicator=True, strategy='median'))]),\n",
       "   posteam                       False\n",
       "   defteam                       False\n",
       "   quarter_seconds_remaining      True\n",
       "   half_seconds_remaining         True\n",
       "   game_seconds_remaining         True\n",
       "   game_half                     False\n",
       "   qtr                           False\n",
       "   goal_to_go                    False\n",
       "   yrdln                          True\n",
       "   ydstogo                        True\n",
       "   posteam_timeouts_remaining     True\n",
       "   defteam_timeouts_remaining     True\n",
       "   score_differential            False\n",
       "   season                        False\n",
       "   dtype: bool)],\n",
       " 'preprocessing__verbose': False,\n",
       " 'preprocessing__categorical': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(add_indicator=True, strategy='most_frequent')),\n",
       "                 ('ohe', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'preprocessing__continuous': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(add_indicator=True, strategy='median'))]),\n",
       " 'preprocessing__categorical__memory': None,\n",
       " 'preprocessing__categorical__steps': [('imputer',\n",
       "   SimpleImputer(add_indicator=True, strategy='most_frequent')),\n",
       "  ('ohe', OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'preprocessing__categorical__verbose': False,\n",
       " 'preprocessing__categorical__imputer': SimpleImputer(add_indicator=True, strategy='most_frequent'),\n",
       " 'preprocessing__categorical__ohe': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessing__categorical__imputer__add_indicator': True,\n",
       " 'preprocessing__categorical__imputer__copy': True,\n",
       " 'preprocessing__categorical__imputer__fill_value': None,\n",
       " 'preprocessing__categorical__imputer__missing_values': nan,\n",
       " 'preprocessing__categorical__imputer__strategy': 'most_frequent',\n",
       " 'preprocessing__categorical__imputer__verbose': 0,\n",
       " 'preprocessing__categorical__ohe__categories': 'auto',\n",
       " 'preprocessing__categorical__ohe__drop': None,\n",
       " 'preprocessing__categorical__ohe__dtype': numpy.float64,\n",
       " 'preprocessing__categorical__ohe__handle_unknown': 'ignore',\n",
       " 'preprocessing__categorical__ohe__sparse': True,\n",
       " 'preprocessing__continuous__memory': None,\n",
       " 'preprocessing__continuous__steps': [('imputer',\n",
       "   SimpleImputer(add_indicator=True, strategy='median'))],\n",
       " 'preprocessing__continuous__verbose': False,\n",
       " 'preprocessing__continuous__imputer': SimpleImputer(add_indicator=True, strategy='median'),\n",
       " 'preprocessing__continuous__imputer__add_indicator': True,\n",
       " 'preprocessing__continuous__imputer__copy': True,\n",
       " 'preprocessing__continuous__imputer__fill_value': None,\n",
       " 'preprocessing__continuous__imputer__missing_values': nan,\n",
       " 'preprocessing__continuous__imputer__strategy': 'median',\n",
       " 'preprocessing__continuous__imputer__verbose': 0,\n",
       " 'gb__ccp_alpha': 0.0,\n",
       " 'gb__criterion': 'friedman_mse',\n",
       " 'gb__init': None,\n",
       " 'gb__learning_rate': 0.1,\n",
       " 'gb__loss': 'deviance',\n",
       " 'gb__max_depth': 3,\n",
       " 'gb__max_features': None,\n",
       " 'gb__max_leaf_nodes': None,\n",
       " 'gb__min_impurity_decrease': 0.0,\n",
       " 'gb__min_impurity_split': None,\n",
       " 'gb__min_samples_leaf': 1,\n",
       " 'gb__min_samples_split': 2,\n",
       " 'gb__min_weight_fraction_leaf': 0.0,\n",
       " 'gb__n_estimators': 100,\n",
       " 'gb__n_iter_no_change': None,\n",
       " 'gb__random_state': None,\n",
       " 'gb__subsample': 1.0,\n",
       " 'gb__tol': 0.0001,\n",
       " 'gb__validation_fraction': 0.1,\n",
       " 'gb__verbose': 0,\n",
       " 'gb__warm_start': False}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T17:31:41.302440Z",
     "start_time": "2021-03-12T17:31:40.754289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Confusion Matrix:\n",
      "            PASS_PRED  RUSH_PRED  FIELD_GOAL_PRED  PUNT_PRED\n",
      "PASS              122         32               42         42\n",
      "RUSH               13         73               15         33\n",
      "FIELD_GOAL         14         22              482          5\n",
      "PUNT               16         13                5       1291\n",
      "\n",
      "-----------------------------\n",
      "Overall Accuracy Score: 88.65%\n",
      "\n",
      "-----------------------------\n",
      "Class Accuracy Scores:\n",
      "PASS: 51.26%\n",
      "RUSH: 54.48%\n",
      "FIELD_GOAL: 92.16%\n",
      "PUNT: 97.43%\n",
      "-----------------------------\n",
      "Go-For-It Accuracy Score: 91.13%\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = final_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_final, labels=y_classes)\n",
    "print('---------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(cm,columns=[y+'_PRED' for y in y_classes],index=y_classes))\n",
    "print ()\n",
    "print('-----------------------------')\n",
    "print (f\"Overall Accuracy Score: {accuracy_score(y_test,y_pred_final)*100:.2f}%\",end='\\n\\n')\n",
    "print('-----------------------------')\n",
    "print (\"Class Accuracy Scores:\",end='\\n')\n",
    "for play_type,acc in (sorted(zip(y_classes,cm.diagonal()/cm.sum(axis=1)),key = lambda x: x[1])):\n",
    "    print (f\"{play_type}: {acc*100:.2f}%\")\n",
    "print('-----------------------------')\n",
    "print(f'Go-For-It Accuracy Score: {go_for_it_metric(y_test,y_pred_final)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    My model performed similarly on the test set as it did during training, ultimately achieving just under 90% accuracy on the test set, which is consistent with my validation results and allows me to conclude that the model is working as expected. This accuracy varied heavily by class in both validation and test predictions, with upwards of 90% of FIELD_GOAL and PUNT plays correctly predicted, but less than 60% of PASS and RUSH plays. These discrepencies makes sense in a game context, given the much more unpredictable nature of PASS and RUSH plays on 4th down. \n",
    "\n",
    "    The model was able to capture a lot of the nuances of play selection in 4th down situations. In the context of a game, this type of model could be especially useful for coaches in predicting play selection of an opposing team in critical 4th down situations. Additionally, further analysis of the model features importances could lead to new insights into play tendencies and potentially key indicators of play selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Look into more features beyond dataset, such individual players or weather (temp, humidity, rain, snow, wind, etc.) \n",
    "\n",
    "2) Test out Deep Learning models to explore potentially better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
